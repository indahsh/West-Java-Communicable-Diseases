> #Library
> library(readxl)
> library(dbscan)

Attaching package: ‘dbscan’

The following object is masked from ‘package:stats’:

    as.dendrogram

> library(factoextra)
Loading required package: ggplot2
Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa
> 
> #Input Data
> input_data = read_excel("D:/04. KERJA/Portofolio/Communicable diseases in West Java (2021)/Communicable Diseases West Java Dataset.xlsx",
+                         sheet = "Data")
> data = as.data.frame(input_data[,-1])
> head(data)
     X1  X2  X3 X4
1 11946 430 220  5
2  4805 117  36  7
3  4673 111  14  3
4  5708 225   2 12
5  4786 172   8  3
6  1995  68  20 15
> 
> #Descriptive Statistics
> calculation <- function(data) {
+   results = matrix(NA, nrow = 3, ncol = 4)
+   colnames(results) <- colnames(data)
+   rownames(results) <- c("Rata-rata", "Nilai Minimum", "Nilai Maksimum")
+   
+   for (i in 1:ncol(data)) {
+     results[1, i] <- round(mean(data[[i]]), 0)
+     results[2, i] <- round(min(data[[i]]), 0)
+     results[3, i] <- round(max(data[[i]]), 0)
+   }
+   
+   return(results)
+ }
> 
> descriptive_statistics <- calculation(data)
> print(descriptive_statistics)
                  X1  X2  X3 X4
Rata-rata       3306 168  49  7
Nilai Minimum    269   4   0  0
Nilai Maksimum 11946 430 220 43
> 
> #Tuberculosis
> #Sort data from highest to lowest
> X1_sorted <- input_data[order(input_data$X1, decreasing = TRUE), ]
> #Create a bar chart
> par(mar = c(11, 4, 1, 0) + 0.1)
> bar_chart.X1 <- barplot(X1_sorted$X1, names.arg = X1_sorted$`Regencies/Cities`,
+                         las = 2, ylim = c(0, 15000))
> #Show the number of cases of each object
> text(x = bar_chart.X1 + 0.2, y = X1_sorted$X1 + 500, labels = X1_sorted$X1, 
+      cex = 0.9, pos = 3, srt = 90)
> #Show the average value
> abline(h = mean(X1_sorted$X1), col = "red", lty = 2)
> text(x = max(bar_chart.X1) - 1.3, y = mean(X1_sorted$X1), 
+      labels = paste(round(mean(X1_sorted$X1), 0)), pos = 3, cex = 0.9)
> 
> #HIV
> #Sort data from highest to lowest
> X2_sorted <- input_data[order(input_data$X2, decreasing = TRUE), ]
> #Create a bar chart
> par(mar = c(11, 4, 1, 0) + 0.1)
> bar_chart.X2 <- barplot(X2_sorted$X2, names.arg = X2_sorted$`Regencies/Cities`,
+                         las = 2, ylim = c(0, 500))
> #Show the number of cases of each object
> text(x = bar_chart.X2 + 0.2, y = X2_sorted$X2 + 10, labels = X2_sorted$X2, 
+      cex = 0.9, pos = 3, srt = 90)
> #Show the average value
> abline(h = mean(X2_sorted$X2), col = "red", lty = 2)
> text(x = max(bar_chart.X2) - 1.3, y = mean(X2_sorted$X2), 
+      labels = paste(round(mean(X2_sorted$X2), 0)), pos = 3, cex = 0.9)
> 
> #Leprosy
> #Sort data from highest to lowest
> X3_sorted <- input_data[order(input_data$X3, decreasing = TRUE), ]
> #Create a bar chart
> par(mar = c(11, 4, 1, 0) + 0.1)
> bar_chart.X3 <- barplot(X3_sorted$X3, names.arg = X3_sorted$`Regencies/Cities`,
+                         las = 2, ylim = c(0, 250))
> #Show the number of cases of each object
> text(x = bar_chart.X3 + 0.2, y = X3_sorted$X3 + 7, labels = X3_sorted$X3, 
+      cex = 0.9, pos = 3, srt = 90)
> #Show the average value
> abline(h = mean(X3_sorted$X3), col = "red", lty = 2)
> text(x = max(bar_chart.X3) - 1.3, y = mean(X3_sorted$X3), 
+      labels = paste(round(mean(X3_sorted$X3), 0)), pos = 3, cex = 0.9)
> 
> #Malaria
> #Sort data from highest to lowest
> X4_sorted <- input_data[order(input_data$X4, decreasing = TRUE), ]
> #Create a bar chart
> par(mar = c(11, 4, 1, 0) + 0.1)
> bar_chart.X4 <- barplot(X4_sorted$X4, names.arg = X4_sorted$`Regencies/Cities`,
+                         las = 2, ylim = c(0, 50))
> #Show the number of cases of each object
> text(x = bar_chart.X4 + 0.2, y = X4_sorted$X4 + 1, labels = X4_sorted$X4, 
+      cex = 0.9, pos = 3, srt = 90)
> #Show the average value
> abline(h = mean(X4_sorted$X4), col = "red", lty = 2)
> text(x = max(bar_chart.X4) - 1.3, y = mean(X4_sorted$X4), 
+      labels = paste(round(mean(X4_sorted$X4), 0)), pos = 3, cex = 0.9)
> 
> #Outlier Detection
> #Mahalanobis Distance
> mahalanobis_distance = mahalanobis(x = data, center = colMeans(data),
+                                    cov = cov(data))
> print(mahalanobis_distance)
 [1] 12.3761593  1.1702688  1.3912498  2.7393541  1.4690304  2.2340906  1.1101356  0.9911451  2.6640221  0.9532113  1.4253990 13.4533569
[13]  2.0431951  0.6812195  1.5182785  4.3114324  1.1555481  2.3164197  5.8336362  1.3492345 12.4956167  4.4251493  5.4555527  1.8897111
[25] 15.6638244  0.8089952  2.0747634
> #Outlier Boundary
> boundary = qchisq(p = 0.95, df = ncol(data)) 
> print(boundary)
[1] 9.487729
> #Outlier
> data[mahalanobis_distance > boundary, ]
      X1  X2  X3 X4
1  11946 430 220  5
12  1701 113 194 19
21  8919  43   5  8
25  1782 342   0 43
> 
> #Nonmulticollinearity Assumption
> #Pearson Correlation
> pearson = cor(data, method = "pearson")
> print(pearson)
            X1        X2          X3          X4
X1  1.00000000 0.4833668  0.45021520 -0.05038203
X2  0.48336675 1.0000000  0.46981800  0.28414926
X3  0.45021520 0.4698180  1.00000000 -0.07607018
X4 -0.05038203 0.2841493 -0.07607018  1.00000000
> #T-Test Statistics
> t_count.X1X1 = cor.test(data$X1, data$X1)
> print(t_count.X1X1)

	Pearson's product-moment correlation

data:  data$X1 and data$X1
t = Inf, df = 25, p-value < 2.2e-16
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 1 1
sample estimates:
cor 
  1 

> t_count.X1X2 = cor.test(data$X1, data$X2)
> print(t_count.X1X2)

	Pearson's product-moment correlation

data:  data$X1 and data$X2
t = 2.7608, df = 25, p-value = 0.01064
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 0.1266091 0.7294001
sample estimates:
      cor 
0.4833668 

> t_count.X1X3 = cor.test(data$X1, data$X3)
> print(t_count.X1X3)

	Pearson's product-moment correlation

data:  data$X1 and data$X3
t = 2.521, df = 25, p-value = 0.01845
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 0.08469082 0.70893828
sample estimates:
      cor 
0.4502152 

> t_count.X1X4 = cor.test(data$X1, data$X4)
> print(t_count.X1X4)

	Pearson's product-moment correlation

data:  data$X1 and data$X4
t = -0.25223, df = 25, p-value = 0.8029
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 -0.4223105  0.3360662
sample estimates:
        cor 
-0.05038203 

> t_count.X2X2 = cor.test(data$X2, data$X2)
> print(t_count.X2X2)

	Pearson's product-moment correlation

data:  data$X2 and data$X2
t = Inf, df = 25, p-value < 2.2e-16
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 1 1
sample estimates:
cor 
  1 

> t_count.X2X3 = cor.test(data$X2, data$X3)
> print(t_count.X2X3)

	Pearson's product-moment correlation

data:  data$X2 and data$X3
t = 2.6611, df = 25, p-value = 0.01341
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 0.1093221 0.7210904
sample estimates:
     cor 
0.469818 

> t_count.X2X4 = cor.test(data$X2, data$X4)
> print(t_count.X2X4)

	Pearson's product-moment correlation

data:  data$X2 and data$X4
t = 1.4818, df = 25, p-value = 0.1509
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 -0.1074693  0.5994357
sample estimates:
      cor 
0.2841493 

> t_count.X3X3 = cor.test(data$X3, data$X3)
> print(t_count.X3X3)

	Pearson's product-moment correlation

data:  data$X3 and data$X3
t = Inf, df = 25, p-value < 2.2e-16
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 1 1
sample estimates:
cor 
  1 

> t_count.X3X4 = cor.test(data$X3, data$X4)
> print(t_count.X3X4)

	Pearson's product-moment correlation

data:  data$X3 and data$X4
t = -0.38146, df = 25, p-value = 0.7061
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 -0.4432702  0.3129917
sample estimates:
        cor 
-0.07607018 

> t_count.X4X4 = cor.test(data$X4, data$X4)
> print(t_count.X4X4)

	Pearson's product-moment correlation

data:  data$X4 and data$X4
t = Inf, df = 25, p-value < 2.2e-16
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 1 1
sample estimates:
cor 
  1 

> #T-Table
> t_table <- qt(0.05/2,27-2,lower.tail = FALSE)
> print(t_table)
[1] 2.059539
> 
> #Principal Component Analysis
> PCA = princomp(data, cor = TRUE, scores = TRUE)
> print(PCA$loadings)

Loadings:
   Comp.1 Comp.2 Comp.3 Comp.4
X1  0.566  0.210  0.712  0.359
X2  0.598 -0.280        -0.751
X3  0.558  0.257 -0.701  0.362
X4  0.105 -0.901         0.420

               Comp.1 Comp.2 Comp.3 Comp.4
SS loadings      1.00   1.00   1.00   1.00
Proportion Var   0.25   0.25   0.25   0.25
Cumulative Var   0.25   0.50   0.75   1.00
> summary(PCA)
Importance of components:
                          Comp.1    Comp.2    Comp.3     Comp.4
Standard deviation     1.3948413 1.0591309 0.7410189 0.61931439
Proportion of Variance 0.4863956 0.2804396 0.1372773 0.09588758
Cumulative Proportion  0.4863956 0.7668352 0.9041124 1.00000000
> #Principal Component Scores
> new_data = as.data.frame(PCA$scores)
> head(new_data)
       Comp.1     Comp.2      Comp.3      Comp.4
1  4.72816309  0.8707409  0.50480616  0.29166350
2 -0.05153570  0.1706464  0.55178736  0.49291974
3 -0.34452715  0.4741455  0.76432291  0.21404615
4  0.49182778 -0.6431985  1.13279988 -0.07494133
5 -0.04316193  0.3061221  0.85144301 -0.21524706
6 -0.97286186 -0.7653280 -0.06543128  0.70710501
> 
> #Euclidean Distance
> euclidean = dist(new_data, method = "euclidean")
> print(euclidean)
           1         2         3         4         5         6         7         8         9        10        11        12        13
2  4.8351178                                                                                                                        
3  5.0953751 0.5485412                                                                                                              
4  4.5571180 1.2718605 1.4721536                                                                                                    
5  4.8437023 0.7808441 0.5576158 1.1341389                                                                                          
6  5.9729531 1.4668757 1.6919509 2.0512400 1.9245101                                                                                
7  6.1518423 1.5175819 1.2835675 2.4258818 1.5994587 1.4189139                                                                      
8  5.5709962 1.4350868 1.3062828 2.3584989 1.4801018 1.7090876 0.8372371                                                            
9  3.9236886 2.0651582 2.3156455 2.5339792 2.2105394 2.7715502 2.7241899 1.9698335                                                  
10 5.6663148 1.4106173 1.1975812 2.2286284 1.3262326 1.6834321 0.7012462 0.3338899 2.1704174                                        
11 5.9611781 1.5986936 1.3221379 2.3053895 1.4317139 1.7068446 0.6044212 0.6826701 2.5181600 0.3768993                              
12 5.1018991 2.9799743 3.4308509 3.5392042 3.5586427 2.7212944 3.4439155 3.0254376 2.2513461 3.2711763 3.5544464                    
13 4.2129572 1.8454169 2.0664022 2.3548834 1.9628412 2.4905430 2.3942771 1.6363800 0.3660090 1.8272645 2.1682896 2.2894312          
14 5.4140355 1.1945711 0.9778319 2.0438976 1.0967485 1.7130161 0.8470227 0.4099731 2.0137534 0.2820204 0.5914323 3.2256652 1.6843088
15 3.7664145 1.7457282 1.8836584 2.1085054 1.6770697 2.7898107 2.5543065 1.8568482 0.7917252 1.9679739 2.2873225 2.9074384 0.7714625
16 3.3402850 2.5667883 2.8003990 3.0260735 2.7112312 3.4716317 3.3654599 2.6198180 0.8392397 2.8292013 3.1891090 2.6210341 1.1754766
17 6.1238841 1.5188720 1.2339675 2.3941885 1.5252442 1.5303656 0.1621246 0.8352136 2.7335834 0.6497510 0.5099782 3.5540746 2.4020675
18 6.7233255 2.0561728 1.9094079 2.9710513 2.2640786 1.4642603 0.7021152 1.3419196 3.1748836 1.3017206 1.1862024 3.4897394 2.8509898
19 5.4190508 2.6448850 2.8466122 2.0143126 2.5138981 2.4188673 3.0071373 2.8203943 2.8625252 2.7099111 2.7159017 3.4493071 2.6389293
20 6.3485713 1.6753360 1.4738303 2.5641959 1.7978851 1.3665777 0.2345389 1.0091017 2.8870664 0.8957453 0.7655743 3.4674418 2.5557194
21 4.9312354 1.7830036 1.8283073 2.0941131 2.0388780 2.7836073 2.8868385 3.0569600 3.4926124 3.0007299 3.1031369 4.2180606 3.3917009
22 5.3323041 1.8811484 1.7036290 1.9613737 1.3677527 2.3278981 1.7786224 1.4236967 2.2269419 1.2224863 1.2225458 3.7483547 1.9051766
23 3.1524958 2.6200691 2.7484149 2.1265978 2.2912518 3.6420609 3.6211360 3.0663555 2.0130986 3.0472144 3.2516890 3.8728510 2.0513949
24 4.8209305 1.5100047 1.9438545 1.1741279 1.8216704 1.5137349 2.4670681 2.3610818 2.3549053 2.3318813 2.4531140 2.6183391 2.1815355
25 6.6071163 4.5329172 4.8856579 3.7898277 4.6862409 3.8886911 5.0724677 5.0867859 4.9456573 5.0154349 5.0130417 4.4246235 4.8174474
26 5.9916243 1.4009606 1.4468669 1.9953563 1.6155171 0.6651120 0.9329193 1.2389714 2.6257879 1.1322050 1.0877811 3.0144794 2.2962779
27 6.6173522 2.0854061 1.8466985 2.9635788 2.1294939 1.7746176 0.5815263 1.0881998 3.0344089 1.0015887 0.8349800 3.6656454 2.6973734
          14        15        16        17        18        19        20        21        22        23        24        25        26
2                                                                                                                                   
3                                                                                                                                   
4                                                                                                                                   
5                                                                                                                                   
6                                                                                                                                   
7                                                                                                                                   
8                                                                                                                                   
9                                                                                                                                   
10                                                                                                                                  
11                                                                                                                                  
12                                                                                                                                  
13                                                                                                                                  
14                                                                                                                                  
15 1.7485489                                                                                                                        
16 2.6400399 1.1193914                                                                                                              
17 0.7892608 2.5218337 3.3657505                                                                                                    
18 1.4921379 3.1324971 3.8340812 0.8289250                                                                                          
19 2.6986344 2.8259003 3.5898597 3.0083900 3.3388319                                                                                
20 1.0640105 2.7562283 3.5430210 0.3624428 0.4838513 3.0639233                                                                      
21 2.7860241 3.0441312 3.6705288 2.8701896 3.3177091 4.0260344 3.0072171                                                            
22 1.1986297 1.8553898 2.8945504 1.6874042 2.3591890 2.0595521 1.9426118 3.4043270                                                  
23 2.8391426 1.5331369 2.1333970 3.5609387 4.2500735 2.6675056 3.8197664 3.5362731 2.3251424                                        
24 2.2193196 2.3099938 2.9722325 2.5072273 2.8126639 1.6435713 2.5372561 2.6768887 2.3111940 2.6085849                              
25 5.0034897 5.0671929 5.5555030 5.1245917 5.1853451 2.6799492 5.0544341 5.3620493 4.6642589 4.7549166 3.0623846                    
26 1.2177659 2.5583739 3.3649164 1.0145984 1.1447852 2.2708316 0.9115762 2.9134124 1.7641951 3.4208663 1.7249713 4.1516712          
27 1.2360189 2.9342120 3.6885691 0.6239727 0.5397781 3.2942465 0.4881440 3.4340623 2.0249895 4.0400926 2.9367598 5.3693764 1.2824706
> 
> #K-Medoids
> #Clustering
> kmedoids <- pam(new_data, 4, metric = "euclidean", medoids = c(9, 5, 7, 19))
> summary(kmedoids)
Medoids:
     ID      Comp.1     Comp.2      Comp.3      Comp.4
[1,]  9  1.13198171  0.5744988 -0.99518034 -0.06202110
[2,]  5 -0.04316193  0.3061221  0.85144301 -0.21524706
[3,]  7 -1.38431459  0.4215752  0.03074638  0.05439231
[4,] 19  0.27066051 -1.8094170 -0.14397316 -1.08406230
Clustering vector:
 [1] 1 2 2 2 2 3 3 3 1 3 3 1 1 3 1 1 3 3 4 3 2 2 1 4 4 3 3
Objective function:
   build     swap 
1.015182 1.015182 

Numerical information per cluster:
     size max_diss   av_diss diameter separation
[1,]    7 3.923689 1.4550153 5.101899  1.6363800
[2,]    6 2.038878 0.9798716 3.404327  0.9778319
[3,]   11 1.418914 0.6383696 1.774618  0.9778319
[4,]    3 2.679949 1.4411735 3.062385  1.1741279

Isolated clusters:
 L-clusters: character(0)
 L*-clusters: character(0)

Silhouette plot information:
   cluster neighbor   sil_width
16       1        2  0.36451067
9        1        2  0.31389748
1        1        2  0.20601936
13       1        2  0.19662923
15       1        2  0.11571040
23       1        2  0.05696505
12       1        3  0.04170127
4        2        4  0.31785597
5        2        3  0.28897170
21       2        3  0.26034176
2        2        3  0.20600592
3        2        3  0.14324807
22       2        3 -0.16510227
20       3        2  0.63494826
7        3        2  0.63337475
17       3        2  0.60961425
27       3        2  0.60848603
18       3        2  0.57712174
11       3        2  0.54404185
10       3        2  0.51714173
8        3        2  0.48540363
26       3        2  0.42737658
14       3        2  0.37773930
6        3        2  0.26349209
25       4        2  0.38300810
19       4        2  0.19463990
24       4        2 -0.18983940
Average silhouette width per cluster:
[1] 0.1850619 0.1752202 0.5162491 0.1292695
Average silhouette width of total data set:
[1] 0.3116038

351 dissimilarities, summarized :
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.1621  1.5221  2.3592  2.5418  3.2387  6.7233 
Metric :  euclidean 
Number of objects : 27

Available components:
 [1] "medoids"    "id.med"     "clustering" "objective"  "isolation"  "clusinfo"   "silinfo"    "diss"       "call"       "data"      
> cluster_kmedoids <- data.frame(input_data$`Regencies/Cities`, kmedoids$cluster)
> names(cluster_kmedoids) <- c("Regencies/Cities", "Cluster")
> print(cluster_kmedoids)
       Regencies/Cities Cluster
1         Bogor Regency       1
2      Sukabumi Regency       2
3       Cianjur Regency       2
4       Bandung Regency       2
5         Garut Regency       2
6   Tasikmalaya Regency       3
7        Ciamis Regency       3
8      Kuningan Regency       3
9       Cirebon Regency       1
10   Majalengka Regency       3
11     Sumedang Regency       3
12    Indramayu Regency       1
13       Subang Regency       1
14   Purwakarta Regency       3
15     Karawang Regency       1
16       Bekasi Regency       1
17 West Bandung Regency       3
18  Pangandaran Regency       3
19           Bogor City       4
20        Sukabumi City       3
21         Bandung City       2
22         Cirebon City       2
23          Bekasi City       1
24           Depok City       4
25          Cimahi City       4
26     Tasikmalaya City       3
27          Banjar City       3
> #Plot
> fviz_cluster(kmedoids, data = new_data, geom = "point", ellipse = FALSE, 
+              show.clust.cent = FALSE, ggtheme = theme_classic(), stand = FALSE)
> 
> #DBSCAN
> #Clustering
> #k = 3
> euclidean_k3 = kNNdist(new_data, k = 3)
> print(euclidean_k3)
 [1] 3.7664145 1.1945711 0.9778319 1.2718605 1.0967485 1.4189139 0.5815263 0.6826701 0.8392397 0.3768993 0.5914323 2.6183391 1.1754766
[14] 0.5914323 1.1193914 1.1754766 0.5099782 0.7021152 2.0595521 0.4838513 2.0388780 1.2225458 2.0513949 1.5137349 3.7898277 0.9329193
[27] 0.5815263
> #K-distance Graph
> kNNdistplot(new_data, k = 3)
> #Border Point
> abline(v = 21)
> #Temporary Epsilon Value
> abline(h = 1.42, col = "red", lty = 2)
> abline(h = 1.27, col = "red", lty = 2)
> abline(h = 1.22, col = "red", lty = 2)
> abline(h = 1.19, col = "red", lty = 2)
> abline(h = 1.18, col = "red", lty = 2)
> abline(h = 1.12, col = "red", lty = 2)
> abline(h = 1.10, col = "red", lty = 2)
> abline(h = 0.98, col = "red", lty = 2)
> abline(h = 0.93, col = "red", lty = 2)
> abline(h = 0.84, col = "red", lty = 2)
> abline(h = 0.70, col = "red", lty = 2)
> abline(h = 0.68, col = "red", lty = 2)
> abline(h = 0.59, col = "red", lty = 2)
> abline(h = 0.58, col = "red", lty = 2)
> abline(h = 0.51, col = "red", lty = 2)
> abline(h = 0.48, col = "red", lty = 2)
> #Cluster
> for (epsilon in c(1.42, 1.27, 1.22, 1.19, 1.18, 1.12, 1.10, 0.98, 0.93, 0.84,
+                   0.70, 0.68, 0.59, 0.58, 0.51, 0.48)) {
+   print(fpc::dbscan(new_data, eps = epsilon, MinPts = 3))
+ }
dbscan Pts=27 MinPts=3 eps=1.42
       0  1 2
border 6  1 0
seed   0 16 4
total  6 17 4
dbscan Pts=27 MinPts=3 eps=1.27
       0  1 2
border 6  2 0
seed   0 15 4
total  6 17 4
dbscan Pts=27 MinPts=3 eps=1.22
       0  1 2
border 6  3 0
seed   0 14 4
total  6 17 4
dbscan Pts=27 MinPts=3 eps=1.19
       0  1 2
border 7  2 0
seed   0 14 4
total  7 16 4
dbscan Pts=27 MinPts=3 eps=1.18
       0  1 2
border 7  2 0
seed   0 14 4
total  7 16 4
dbscan Pts=27 MinPts=3 eps=1.12
       0  1 2
border 9  1 0
seed   0 13 4
total  9 14 4
dbscan Pts=27 MinPts=3 eps=1.1
       0  1 2
border 9  1 1
seed   0 13 3
total  9 14 4
dbscan Pts=27 MinPts=3 eps=0.98
       0  1 2
border 9  1 1
seed   0 13 3
total  9 14 4
dbscan Pts=27 MinPts=3 eps=0.93
       0 1  2 3
border 9 0  1 1
seed   0 3 10 3
total  9 3 11 4
dbscan Pts=27 MinPts=3 eps=0.84
        0 1 2 3
border 11 0 0 1
seed    0 3 9 3
total  11 3 9 4
dbscan Pts=27 MinPts=3 eps=0.7
        0 1 2
border 15 2 0
seed    0 1 9
total  15 3 9
dbscan Pts=27 MinPts=3 eps=0.68
        0 1 2
border 15 2 0
seed    0 1 9
total  15 3 9
dbscan Pts=27 MinPts=3 eps=0.59
        0 1 2
border 15 2 0
seed    0 1 9
total  15 3 9
dbscan Pts=27 MinPts=3 eps=0.58
        0 1 2
border 15 2 0
seed    0 1 9
total  15 3 9
dbscan Pts=27 MinPts=3 eps=0.51
        0 1
border 18 2
seed    0 7
total  18 9
dbscan Pts=27 MinPts=3 eps=0.48
        0 1 2
border 20 0 1
seed    0 3 3
total  20 3 4
> 
> #Clustering
> #k = 4
> euclidean_k4 = kNNdist(new_data, k = 4)
> print(euclidean_k4)
 [1] 3.9236886 1.2718605 1.1975812 1.4721536 1.1341389 1.4642603 0.6044212 0.8352136 1.9698335 0.6497510 0.6044212 2.6210341 1.6363800
[14] 0.7892608 1.5331369 2.1333970 0.6239727 0.8289250 2.2708316 0.4881440 2.0941131 1.3677527 2.1265978 1.6435713 3.8886911 1.0145984
[27] 0.6239727
> #K-distance Graph
> kNNdistplot(new_data, k = 4)
> #Border Point
> abline(v = 24)
> #Temporary Epsilon Value
> abline(h = 2.13, col = "red", lty = 2)
> abline(h = 2.09, col = "red", lty = 2)
> abline(h = 1.97, col = "red", lty = 2)
> abline(h = 1.64, col = "red", lty = 2)
> abline(h = 1.53, col = "red", lty = 2)
> abline(h = 1.47, col = "red", lty = 2)
> abline(h = 1.46, col = "red", lty = 2)
> abline(h = 1.37, col = "red", lty = 2)
> abline(h = 1.27, col = "red", lty = 2)
> abline(h = 1.20, col = "red", lty = 2)
> abline(h = 1.13, col = "red", lty = 2)
> abline(h = 1.01, col = "red", lty = 2)
> abline(h = 0.83, col = "red", lty = 2)
> abline(h = 0.79, col = "red", lty = 2)
> abline(h = 0.65, col = "red", lty = 2)
> abline(h = 0.62, col = "red", lty = 2)
> abline(h = 0.60, col = "red", lty = 2)
> #Cluster
> for (epsilon in c(2.13, 2.09, 1.97, 1.64, 1.53, 1.47, 1.46, 1.37, 1.27, 1.20, 
+                   1.13, 1.01, 0.83, 0.79, 0.65, 0.62, 0.60)) {
+   print(fpc::dbscan(new_data, eps = epsilon, MinPts = 4))
+ }
dbscan Pts=27 MinPts=4 eps=2.13
       0  1
border 3  0
seed   0 24
total  3 24
dbscan Pts=27 MinPts=4 eps=2.09
       0  1
border 3  0
seed   0 24
total  3 24
dbscan Pts=27 MinPts=4 eps=1.97
       0  1
border 3  3
seed   0 21
total  3 24
dbscan Pts=27 MinPts=4 eps=1.64
       0  1
border 5  1
seed   0 21
total  5 22
dbscan Pts=27 MinPts=4 eps=1.53
       0  1 2
border 6  0 0
seed   0 17 4
total  6 17 4
dbscan Pts=27 MinPts=4 eps=1.47
       0  1 2
border 6  1 0
seed   0 16 4
total  6 17 4
dbscan Pts=27 MinPts=4 eps=1.46
       0  1 2
border 6  1 0
seed   0 16 4
total  6 17 4
dbscan Pts=27 MinPts=4 eps=1.37
       0  1 2
border 6  2 0
seed   0 15 4
total  6 17 4
dbscan Pts=27 MinPts=4 eps=1.27
       0  1 2
border 7  2 0
seed   0 14 4
total  7 16 4
dbscan Pts=27 MinPts=4 eps=1.2
       0  1 2
border 7  3 0
seed   0 13 4
total  7 16 4
dbscan Pts=27 MinPts=4 eps=1.13
       0  1 2
border 9  2 2
seed   0 12 2
total  9 14 4
dbscan Pts=27 MinPts=4 eps=1.01
       0  1 2
border 9  3 3
seed   0 11 1
total  9 14 4
dbscan Pts=27 MinPts=4 eps=0.83
        0 1
border 18 0
seed    0 9
total  18 9
dbscan Pts=27 MinPts=4 eps=0.79
        0 1
border 18 0
seed    0 9
total  18 9
dbscan Pts=27 MinPts=4 eps=0.65
        0 1
border 18 2
seed    0 7
total  18 9
dbscan Pts=27 MinPts=4 eps=0.62
        0 1
border 18 2
seed    0 7
total  18 9
dbscan Pts=27 MinPts=4 eps=0.6
        0 1
border 18 2
seed    0 7
total  18 9
> 
> #Best MinPts and Epsilon Values
> dbscan <- dbscan(new_data, eps = 1.37, MinPts = 4)
Warning message:
In dbscan(new_data, eps = 1.37, MinPts = 4) :
  converting argument MinPts (fpc) to minPts (dbscan)!
> print(dbscan)
DBSCAN clustering for 27 objects.
Parameters: eps = 1.37, minPts = 4
Using euclidean distances and borderpoints = TRUE
The clustering contains 2 cluster(s) and 6 noise points.

 0  1  2 
 6 17  4 

Available fields: cluster, eps, minPts, dist, borderPoints
> #Cluster
> cluster_dbscan <- data.frame(input_data$`Regencies/Cities`, dbscan$cluster)
> names(cluster_dbscan) <- c("Regencies/Cities", "Cluster")
> print(cluster_dbscan)
       Regencies/Cities Cluster
1         Bogor Regency       0
2      Sukabumi Regency       1
3       Cianjur Regency       1
4       Bandung Regency       1
5         Garut Regency       1
6   Tasikmalaya Regency       1
7        Ciamis Regency       1
8      Kuningan Regency       1
9       Cirebon Regency       2
10   Majalengka Regency       1
11     Sumedang Regency       1
12    Indramayu Regency       0
13       Subang Regency       2
14   Purwakarta Regency       1
15     Karawang Regency       2
16       Bekasi Regency       2
17 West Bandung Regency       1
18  Pangandaran Regency       1
19           Bogor City       0
20        Sukabumi City       1
21         Bandung City       0
22         Cirebon City       1
23          Bekasi City       0
24           Depok City       1
25          Cimahi City       0
26     Tasikmalaya City       1
27          Banjar City       1
> #Plot
> fviz_cluster(dbscan, data = new_data, geom = "point", ellipse = FALSE, 
+              show.clust.cent = FALSE, ggtheme = theme_classic(), stand = FALSE)
> 
> #Cluster Validation
> #K-Medoids
> silhouette_kmedoids <- silhouette(kmedoids$cluster, dist(new_data))
> silhouette_kmedoids <- summary(silhouette_kmedoids)$avg.width
> print(silhouette_kmedoids)
[1] 0.3116038
> #DBSCAN
> silhouette_dbscan <- silhouette(dbscan$cluster, dist(new_data))
> silhouette_dbscan <- summary(silhouette_dbscan)$avg.width
> print(silhouette_dbscan)
[1] 0.2954324
> 
> #Selection of a Better Method
> comparison <- data.frame(
+   methods = c("K-Medoids", "DBSCAN"),
+   silhouette = c(silhouette_kmedoids, silhouette_dbscan)
+ )
> print(comparison)
    methods silhouette
1 K-Medoids  0.3116038
2    DBSCAN  0.2954324
> 
> #Characteristics
> #Cluster 1
> cluster_1 = read_excel("D:/04. KERJA/Portofolio/Communicable diseases in West Java (2021)/Communicable Diseases West Java Dataset.xlsx",
+                        sheet = "Cluster 1")
> data_cluster1 = as.data.frame(cluster_1)
> head(data_cluster1)
   Regencies/Cities    X1  X2  X3 X4
1     Bogor Regency 11946 430 220  5
2   Cirebon Regency  3383 232 144  3
3 Indramayu Regency  1701 113 194 19
4    Subang Regency  2912 222 124  3
5  Karawang Regency  4528 244 107  0
6    Bekasi Regency  4798 239 180  0
> average_cluster1 = colMeans(data_cluster1[,-1])
> round(average_cluster1, 2)
     X1      X2      X3      X4 
5045.57  267.14  149.71    4.71 
> 
> #Cluster 2
> cluster_2 = read_excel("D:/04. KERJA/Portofolio/Communicable diseases in West Java (2021)/Communicable Diseases West Java Dataset.xlsx",
+                        sheet = "Cluster 2")
> data_cluster2 = as.data.frame(cluster_2)
> head(data_cluster2)
  Regencies/Cities   X1  X2 X3 X4
1 Sukabumi Regency 4805 117 36  7
2  Cianjur Regency 4673 111 14  3
3  Bandung Regency 5708 225  2 12
4    Garut Regency 4786 172  8  3
5     Bandung City 8919  43  5  8
6     Cirebon City 1910 254  5  0
> average_cluster2 = colMeans(data_cluster2[,-1])
> round(average_cluster2, 2)
     X1      X2      X3      X4 
5133.50  153.67   11.67    5.50 
> 
> #Cluster 3
> cluster_3 = read_excel("D:/04. KERJA/Portofolio/Communicable diseases in West Java (2021)/Communicable Diseases West Java Dataset.xlsx",
+                        sheet = "Cluster 3")
> data_cluster3 = as.data.frame(cluster_3)
> head(data_cluster3)
     Regencies/Cities   X1  X2 X3 X4
1 Tasikmalaya Regency 1995  68 20 15
2      Ciamis Regency 1606  58  5  2
3    Kuningan Regency 1651 113 47  0
4  Majalengka Regency 1723 123 26  0
5    Sumedang Regency 1372 120  3  0
6  Purwakarta Regency 2410 130 31  0
> average_cluster3 = colMeans(data_cluster3[,-1])
> round(average_cluster3, 2)
     X1      X2      X3      X4 
1442.82   78.64   13.27    3.18 
> 
> #Cluster 4
> cluster_4 = read_excel("D:/04. KERJA/Portofolio/Communicable diseases in West Java (2021)/Communicable Diseases West Java Dataset.xlsx",
+                        sheet = "Cluster 4")
> data_cluster4 = as.data.frame(cluster_4)
> head(data_cluster4)
  Regencies/Cities   X1  X2 X3 X4
1       Bogor City 1440 333  9 18
2       Depok City 4042 199 41 19
3      Cimahi City 1782 342  0 43
> average_cluster4 = colMeans(data_cluster4[,-1])
> round(average_cluster4, 2)
     X1      X2      X3      X4 
2421.33  291.33   16.67   26.67 